---
title: "Interpretable Machine Learning"
author: "Computation Skills Workshop"
output: rcfss::xaringan
---

```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE)
knitr::opts_chunk$set(
  echo = FALSE,
  cache = TRUE,
  message = FALSE,
  warning = FALSE,
  collapse = TRUE,
  fig.retina = 2, fig.width = 12
)

library(tidyverse)
library(tidymodels)
library(ranger)
library(here)
library(DALEX)
library(DALEXtra)
library(lime)
library(patchwork)
library(rcfss)
library(knitr)
library(here)
library(countdown)
library(flipbookr)

set.seed(123)
theme_set(theme_minimal(base_size = rcfss::base_size))
```

class: inverse, center, middle

$$\newcommand{\E}{\mathrm{E}} \newcommand{\Var}{\mathrm{Var}} \newcommand{\Cov}{\mathrm{Cov}} \newcommand{\se}{\text{se}} \newcommand{\Lagr}{\mathcal{L}} \newcommand{\lagr}{\mathcal{l}}$$

# Interpreting and explaining

---

# Interpretation

> Interpretability is the degree to which a human can understand the cause of a decision.

--

> Interpretability is the degree to which a human can consistently predict the model's result.

.footnote[
Miller, Tim. "Explanation in artificial intelligence: Insights from the social sciences." arXiv Preprint arXiv:1706.07269. (2017).

Kim, Been, Rajiv Khanna, and Oluwasanmi O. Koyejo. "Examples are not enough, learn to criticize! Criticism for interpretability." Advances in Neural Information Processing Systems (2016).
]

---

# Explanation

**Answer to the "why" question**

- Why did the government collapse?
- Why was my loan rejected?
- Why have we not been contacted by alien life yet?

.footnote[Miller, Tim. "Explanation in artificial intelligence: Insights from the social sciences." arXiv Preprint arXiv:1706.07269. (2017).]


--

Focus on specific observations

--

Good explanations are:

- Contrastive
- Selected
- Social
- Truthful
- Generalizable

---

# Global vs. local methods

- Interpretation $\leadsto$ global methods
- Explanation $\leadsto$ local methods

---

# White-box models

Models that lend themselves naturally to interpretation:

- Linear regression
- Logistic regression
- Generalized linear model
- Decision tree

---

# Black-box model

```{r fig.align = 'center', echo = FALSE}
include_graphics(path = "https://imgs.xkcd.com/comics/machine_learning.png")
```

---

# Black-box models

- Random forests
- Boosted trees
- Neural networks
- Deep learning

---

class: inverse

```{r fig.align = "center"}
include_graphics(path = "https://media.giphy.com/media/H8LPekEB8uAFXgw97u/giphy.gif")
```

---

# Predicting student debt

- [College Scorecard](https://collegescorecard.ed.gov/)
- [`rscorecard`](https://github.com/btskinner/rscorecard)

---

# Predicting student debt

```{r get-data, echo = FALSE}
# import data and model
load(here("data", "models.Rdata"))
```

```{r skim-data, dependson = "get-data", echo = FALSE}
glimpse(scorecard)
```

---

# Construct some models

```{r model-stats, dependson = "get-data", echo = FALSE}
# predict test set for both models and plot
test_preds <- bind_rows(
  `Random forest` = predict(rf_wf, new_data = scorecard_test) %>% bind_cols(scorecard_test),
  `Penalized regression` = predict(glmnet_wf, new_data = scorecard_test) %>% bind_cols(scorecard_test),
  `K nearest neighbors` = predict(kknn_wf, new_data = scorecard_test) %>% bind_cols(scorecard_test),
  .id = "model"
)

# calculate test set RMSE
test_rmse <- test_preds %>%
  group_by(model) %>%
  rmse(truth = debt, estimate = .pred) %>%
  mutate(.estimate = scales::dollar(.estimate, accuracy = 1))

ggplot(data = test_preds, mapping = aes(x = debt, y = .pred)) +
  geom_abline(linetype = 2) +
  geom_point(alpha = 0.25) +
  geom_text(mapping = aes(x = 10000, y = 27000, label = glue::glue("RMSE: {.estimate}")),
            data = test_rmse, size = 5) +
  facet_wrap(vars(model)) +
  scale_x_continuous(labels = scales::dollar) +
  scale_y_continuous(labels = scales::dollar) +
  coord_obs_pred() +
  labs(
    x = "Average student debt",
    y = "Predicted student debt"
  )
```

---

class: inverse, center, middle

# Global interpretation methods

---

class: inverse, center, middle

# Permutation-based feature importance

---

# Permutation-based feature importance

* Calculate the increase in the model's prediction error after **permuting** the feature
    * Randomly shuffle the feature's values across observations
* Important feature
* Unimportant feature

--

```
For any given loss function do
1: compute loss function for original model
2: for variable i in {1,...,p} do
     | randomize values
     | apply given ML model
     | estimate loss function
     | compute feature importance (permuted loss / original loss)
   end
3. Sort variables by descending feature importance   
```

---

# Random forest feature importance

```{r explainers, dependons = "get-data"}
explainer_glmnet <- explain_tidymodels(
  model = glmnet_wf,
  data = scorecard_train %>% select(-debt),
  y = scorecard_train$debt,
  label = "penalized regression",
  verbose = FALSE
)

explainer_rf <- explain_tidymodels(
  model = rf_wf,
  data = scorecard_train %>% select(-debt),
  y = scorecard_train$debt,
  label = "random forest",
  verbose = FALSE
)

explainer_kknn <- explain_tidymodels(
  model = kknn_wf,
  data = scorecard_train %>% select(-debt),
  y = scorecard_train$debt,
  label = "k nearest neighbors",
  verbose = FALSE
)
```

```{r vip-rf, dependson = "explainers"}
# random forest model first
vip_rf <- model_parts(explainer_rf, N = NULL)
plot(vip_rf) +
  theme_minimal(base_size = rcfss::base_size) +
  theme(legend.position = "none")
```

---

```{r vip-all, dependson = "explainers"}
# plot variable importance
ggplot_imp <- function(...) {
  obj <- list(...)
  metric_name <- attr(obj[[1]], "loss_name")
  metric_lab <- paste(metric_name, 
                      "after permutations\n(higher indicates more important)")
  
  full_vip <- bind_rows(obj) %>%
    filter(variable != "_baseline_")
  
  perm_vals <- full_vip %>% 
    filter(variable == "_full_model_") %>% 
    group_by(label) %>% 
    summarise(dropout_loss = mean(dropout_loss))
  
  p <- full_vip %>%
    filter(variable != "_full_model_") %>% 
    mutate(variable = fct_reorder(variable, dropout_loss)) %>%
    ggplot(aes(dropout_loss, variable)) 
  if(length(obj) > 1) {
    p <- p + 
      facet_wrap(vars(label)) +
      geom_vline(data = perm_vals, aes(xintercept = dropout_loss, color = label),
                 size = 1.4, lty = 2, alpha = 0.7) +
      geom_boxplot(aes(color = label, fill = label), alpha = 0.2)
  } else {
    p <- p + 
      geom_vline(data = perm_vals, aes(xintercept = dropout_loss),
                 size = 1.4, lty = 2, alpha = 0.7) +
      geom_boxplot(fill = "#91CBD765", alpha = 0.4)
    
  }
  p +
    theme(legend.position = "none") +
    labs(x = metric_lab, 
         y = NULL,  fill = NULL,  color = NULL)
}

vip_rf <- model_parts(explainer_rf, N = NULL)
vip_glmnet <- model_parts(explainer_glmnet, N = NULL)
vip_kknn <- model_parts(explainer_kknn, N = NULL)

ggplot_imp(vip_rf, vip_glmnet, vip_kknn)
```

---

class: inverse, center, middle

# Partial dependence plots

---

# Individual conditional expectation

- *Ceteris peribus* - "other things held constant"
- Marginal effect a feature has on the predictor
- Plot one line per observation that shows how the observation's prediction changes when a feature changes
- PDP is average of all ICEs


--


```
For a selected predictor (x)
1. Determine grid space of j evenly spaced values across distribution of x
2: for value i in {1,...,j} of grid space do
     | set x to i for all observations
     | apply given ML model
     | estimate predicted value
     | if PDP: average predicted values across all observations
   end
```

---

# Net cost

```{r pdp-netcost, dependson = "explainers"}
# basic pdp for RF model and netcost variable
pdp_netcost <- model_profile(explainer_rf, variables = "netcost", N = 100)

## PDP with ICE curves
plot(pdp_netcost, geom = "profiles")
```

---

# Type

```{r pdp-type, dependson = "explainers"}
# PDP for type
model_profile(explainer_rf, variables = "type", N = NULL) %>%
  plot()
```

---

class: inverse, center, middle

# Local methods

---

class: inverse, center, middle

# Shapley values


---

class: inverse, center, middle

# LIME


