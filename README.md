## Overview

Machine learning algorithms are widely used in data science applications and have significant potential to improve predictions and understanding of social scientific processes. However machine learning models generally do not explain their predictions -- they simply seek to minimize some loss function and provide for a given observation the probability of an event occurring. In many applications researchers need to be able to explain why the model made one prediction over another. This emphasis on **interpretability** and **explanation** is directly relevant to many social scientific questions, and can provide necessary context for decision makers who need to use machine learning models but lack a strong technical background. In this workshop we introduce several techniques for interpreting black box models using model-agnostic techniques.

## Objectives

- Define interpretation and explanation, and their importance to machine learning
- Identify model-agnostic methods for creating interpretations/explanations
- Implement techniques for creating global model-agnostic explanations in R
- Implement techniques for creating local model-agnostic explanations in R

## Audience

This workshop is designed for individuals with introductory-to-intermediate knowledge of machine learning algorithms, as well as experience training machine learning models using R. Prior experience with [`tidymodels`](https://www.tidymodels.org/) is helpful, but not required.

## Location

Room 295 in [1155 E 60th St](https://goo.gl/maps/7n7wDsd9mjnfRBtR8).

## Prework

- Register for this workshop. Due to the current public health crisis, all participants must register in advance using [this form.](https://forms.gle/wgEVhripKHjzNEzDA)
- Please sign up for a free [RStudio Cloud account](https://rstudio.cloud).
- Once you have created your RStudio Cloud account, [join the workshop organization.](https://rstudio.cloud/spaces/177434/join?access_code=cGV7c0V8%2Bpr0kFC5NkOX%2FgxNNhIm3PchWX1CjdBf)

## Links

