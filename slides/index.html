<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Interpretable Machine Learning</title>
    <meta charset="utf-8" />
    <meta name="author" content="Computation Skills Workshop" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <link href="libs/remark-css/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css/lucy-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Interpretable Machine Learning
### Computation Skills Workshop

---




class: inverse, center, middle

`$$\newcommand{\E}{\mathrm{E}} \newcommand{\Var}{\mathrm{Var}} \newcommand{\Cov}{\mathrm{Cov}} \newcommand{\se}{\text{se}} \newcommand{\Lagr}{\mathcal{L}} \newcommand{\lagr}{\mathcal{l}}$$`

# Interpreting and explaining

---

# Interpretation

&gt; Interpretability is the degree to which a human can understand the cause of a decision.

--

&gt; Interpretability is the degree to which a human can consistently predict the model's result.

.footnote[
Miller, Tim. "Explanation in artificial intelligence: Insights from the social sciences." arXiv Preprint arXiv:1706.07269. (2017).

Kim, Been, Rajiv Khanna, and Oluwasanmi O. Koyejo. "Examples are not enough, learn to criticize! Criticism for interpretability." Advances in Neural Information Processing Systems (2016).
]

---

# Explanation

**Answer to the "why" question**

- Why did the government collapse?
- Why was my loan rejected?
- Why have we not been contacted by alien life yet?

.footnote[Miller, Tim. "Explanation in artificial intelligence: Insights from the social sciences." arXiv Preprint arXiv:1706.07269. (2017).]


--

Focus on specific observations

--

Good explanations are:

- Contrastive
- Selected
- Social
- Truthful
- Generalizable

---

# Global vs. local methods

- Interpretation `\(\leadsto\)` global methods
- Explanation `\(\leadsto\)` local methods

---

# White-box models

Models that lend themselves naturally to interpretation:

- Linear regression
- Logistic regression
- Generalized linear model
- Decision tree

---

# Black-box model

&lt;img src="https://imgs.xkcd.com/comics/machine_learning.png" style="display: block; margin: auto;" /&gt;

---

# Black-box models

- Random forests
- Boosted trees
- Neural networks
- Deep learning

---

class: inverse

&lt;img src="https://media.giphy.com/media/H8LPekEB8uAFXgw97u/giphy.gif" style="display: block; margin: auto;" /&gt;

---

# Predicting student debt

- [College Scorecard](https://collegescorecard.ed.gov/)
- [`rscorecard`](https://github.com/btskinner/rscorecard)

---

# Predicting student debt




```
## Rows: 1,732
## Columns: 14
## $ unitid    &lt;dbl&gt; 100654, 100663, 100706, 100724, 100751, 100830, 100858, 1009…
## $ name      &lt;chr&gt; "Alabama A &amp; M University", "University of Alabama at Birmin…
## $ state     &lt;chr&gt; "AL", "AL", "AL", "AL", "AL", "AL", "AL", "AL", "AL", "AL", …
## $ type      &lt;fct&gt; "Public", "Public", "Public", "Public", "Public", "Public", …
## $ admrate   &lt;dbl&gt; 0.9175, 0.7366, 0.8257, 0.9690, 0.8268, 0.9044, 0.8067, 0.53…
## $ satavg    &lt;dbl&gt; 939, 1234, 1319, 946, 1261, 1082, 1300, 1230, 1066, NA, 1076…
## $ cost      &lt;dbl&gt; 23053, 24495, 23917, 21866, 29872, 19849, 31590, 32095, 3431…
## $ netcost   &lt;dbl&gt; 14990, 16953, 15860, 13650, 22597, 13987, 24104, 22107, 2071…
## $ avgfacsal &lt;dbl&gt; 69381, 99441, 87192, 64989, 92619, 71343, 96642, 56646, 5400…
## $ pctpell   &lt;dbl&gt; 0.7019, 0.3512, 0.2536, 0.7627, 0.1772, 0.4644, 0.1455, 0.23…
## $ comprate  &lt;dbl&gt; 0.2974, 0.6340, 0.5768, 0.3276, 0.7110, 0.3401, 0.7911, 0.69…
## $ firstgen  &lt;dbl&gt; 0.3658281, 0.3412237, 0.3101322, 0.3434343, 0.2257127, 0.381…
## $ debt      &lt;dbl&gt; 15250, 15085, 14000, 17500, 17671, 12000, 17500, 16000, 1425…
## $ locale    &lt;fct&gt; City, City, City, City, City, City, City, City, City, Suburb…
```

---

# Construct some models

&lt;img src="index_files/figure-html/model-stats-1.png" width="864" /&gt;

---

class: inverse, center, middle

# Global interpretation methods

---

class: inverse, center, middle

# Permutation-based feature importance

---

# Permutation-based feature importance

* Calculate the increase in the model's prediction error after **permuting** the feature
    * Randomly shuffle the feature's values across observations
* Important feature
* Unimportant feature

--

```
For any given loss function do
1: compute loss function for original model
2: for variable i in {1,...,p} do
     | randomize values
     | apply given ML model
     | estimate loss function
     | compute feature importance (permuted loss / original loss)
   end
3. Sort variables by descending feature importance   
```

---

# Random forest feature importance



&lt;img src="index_files/figure-html/vip-rf-1.png" width="864" /&gt;

---

&lt;img src="index_files/figure-html/vip-all-1.png" width="864" /&gt;

---

class: inverse, center, middle

# Partial dependence plots

---

# Individual conditional expectation

- *Ceteris peribus* - "other things held constant"
- Marginal effect a feature has on the predictor
- Plot one line per observation that shows how the observation's prediction changes when a feature changes
- PDP is average of all ICEs


--


```
For a selected predictor (x)
1. Determine grid space of j evenly spaced values across distribution of x
2: for value i in {1,...,j} of grid space do
     | set x to i for all observations
     | apply given ML model
     | estimate predicted value
     | if PDP: average predicted values across all observations
   end
```

---

# Net cost

&lt;img src="index_files/figure-html/pdp-netcost-1.png" width="864" /&gt;

---

# Type

&lt;img src="index_files/figure-html/pdp-type-1.png" width="864" /&gt;

---

class: inverse, center, middle

# Local methods

---

class: inverse, center, middle

# Shapley values



---

class: inverse, center, middle

# LIME

---

# LIME

* Global `\(\rightarrow\)` local
* Interpretable model used to explain individual predictions of a black box model
* Assumes every complex model is linear on a local scale
* Fit a simple model around a single observation to mimic how the global model behaves at that locality
* Simple model explains the predictions of the complex model **locally**
    * Local fidelity
    * Does not require global fidelity

---

# LIME

1. For each prediction to explain, permute the observation `\(n\)` times
1. Let the complex model predict the outcome of all permuted observations
1. Calculate the distance from all permutations to the original observation
1. Convert the distance to a similarity score
1. Select `\(m\)` features best describing the complex model outcome from the permuted data
1. Fit a simple model to the permuted data, explaining the complex model outcome with the `\(m\)` features from the permuted data weighted by its similarity to the original observation
1. Extract the feature weights from the simple model and use these as explanations for the complex models local behavior

---

# `\(10\)` nearest neighbors

&lt;img src="index_files/figure-html/unnamed-chunk-3-1.png" width="864" /&gt;

---

# Random forest

&lt;img src="index_files/figure-html/unnamed-chunk-4-1.png" width="864" /&gt;




    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://cfss.uchicago.edu/slides/macros.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightLanguage": "r",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
